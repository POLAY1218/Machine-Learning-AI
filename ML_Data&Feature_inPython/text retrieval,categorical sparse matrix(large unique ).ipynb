{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# information retrieval for text documents.\n",
    "#### Let's say you want to search for a query \"The good book\" meaning you want to search for all the documents that are  relevant to this query on  some search engine.one way is to  get rid of all the documents that do not  contain all those  three words.And  even after that filtration, we will probably be having a lot of documents available.In those documents, it is possible to rank the top document based on the count or frequency of these words as they appear in that document.For example, if a particular document have all those 3 terms(dont have to be together, just their total frequency)appear many times then  retrieve the document.And this is sometimes called the count vectorizer or the count features, basically just count the number of occurrences of word sometimes called the term frequency.So retrieve the document based on the term frequency.!The word 'The' comes up far more frequently in any document in english language compared to good or book . So to fix this bias another term is used called TF-IDF which is term frequency inverted document frequency.  What it means is weighted score is added on top of term frequency where words with lower frequency get higher higher weights than words with higher frequency in a document(or paragraph or string). So term fequency is implemented wrt to tf-idf.These techniques are commonly used in text mining and text processing. Once text is converted into numerical feature vector rest of the story is same as before in ml data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer # first we would try term frequncy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ['the problem of evil of evil extra extra ','of the extra evil queen','the extra extra extra horizon of the problem of ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x7 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(sample)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>extra</th>\n",
       "      <th>horizon</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   evil  extra  horizon  of  problem  queen  the\n",
       "0     2      2        0   2        1      0    1\n",
       "1     1      1        0   1        0      1    1\n",
       "2     0      3        1   2        1      0    2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(X.toarray(),columns=vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abv the output is showing 3 datapoints and the fequency of different terms are appearing in each datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>extra</th>\n",
       "      <th>horizon</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619346</td>\n",
       "      <td>0.480977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480977</td>\n",
       "      <td>0.309673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.469417</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617227</td>\n",
       "      <td>0.364544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.646623</td>\n",
       "      <td>0.364942</td>\n",
       "      <td>0.431082</td>\n",
       "      <td>0.277548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       evil     extra   horizon        of   problem     queen       the\n",
       "0  0.619346  0.480977  0.000000  0.480977  0.309673  0.000000  0.240489\n",
       "1  0.469417  0.364544  0.000000  0.364544  0.000000  0.617227  0.364544\n",
       "2  0.000000  0.646623  0.364942  0.431082  0.277548  0.000000  0.431082"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(sample)\n",
    "#import pandas as pd\n",
    "pd.DataFrame(X.toarray(),columns=vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tf-idf seems to have a complex scoring system depening on multiple factors, however those variables and factors would \n",
    "#vary from the dictionary of the language to language he said"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical features (w lots of unique values)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'p':85,'r':4,'nH':'QA'},\n",
    "       {'p':70,'r':3,'nH':'FM'},  #the sample data has 4 datapoints and feature space is 3d\n",
    "       {'p':65,'r':3,'nH':'WF'},\n",
    "       {'p':60,'r':2,'nH':'FM'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer #to convert our dataset into feature vector format , for categorical data\n",
    "#the dictvectorizer module would take care of categorical variable by doing one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0, 85,  4],\n",
       "       [ 1,  0,  0, 70,  3],\n",
       "       [ 0,  0,  1, 65,  3],\n",
       "       [ 1,  0,  0, 60,  2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = DictVectorizer(sparse=False,dtype=int)\n",
    "vec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nH=FM', 'nH=QA', 'nH=WF', 'p', 'r'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names_out() # we got 5 features now instead of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  When we have a categorical feature with a large number of unique values. say our total number of datapoints is 100 and unique values of our categorical feature is 80 , which means that one categorical feature would extend to 80 features due to once hot encoding.And that means that the dimensionality of the data may increase drastically.but one property of one hot encoding is even though the dimensionality increase drastically, the matrix that we come up with contains mostly zeros which is a sparse matrix.And there are efficient ways to handle with the sparse matrices.And if we have that kind of situation then in our dictvectorizer we should switch the sparse as true so that of featrue matrix is treated as sparse matrix and would be processed in a memory in an efficient way designed to handle sparse matrices.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
